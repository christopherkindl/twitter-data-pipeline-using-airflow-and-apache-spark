{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #requires pip install\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = config.consumer_key\n",
    "consumer_secret = config.consumer_secret\n",
    "access_token = config.access_token\n",
    "access_token_secret = config.access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv ('/Users/christopherkindl/working/data-engineering-group-assignment/\\\n",
    "01_web_scraping/Transport Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a smiley face U+2764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is a smiley face U+2764'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This is a smiley face U+2764'\n",
    "print(text)\n",
    "deEmojify(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test query\n",
    "number_of_tweets = 10\n",
    "tweets = []\n",
    "station = []\n",
    "date = []\n",
    "\n",
    "number_of_stations = 30\n",
    "\n",
    "for index in range(len(stations[:number_of_stations])):\n",
    "    for i in tweepy.Cursor(api.search, q = 'london', lang = 'en', tweet_mode='extended', geocode= \\\n",
    "                           str(stations['Latitude'][index])+','+str(stations['Longitude'][index])+',1km').\\\n",
    "        items(number_of_tweets):\n",
    "        tweets.append(i.full_text)\n",
    "        station.append(stations['Station'][index])\n",
    "        date.append(i.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'tweets': tweets, 'date':date, 'station': station})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paintpeteuk @BBCRadio3 Have seen it performed...</td>\n",
       "      <td>2021-05-01 20:06:22</td>\n",
       "      <td>Abbey Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just posted a photo @ Abbey Road, London, UK h...</td>\n",
       "      <td>2021-05-01 16:01:07</td>\n",
       "      <td>Abbey Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbey Road #throwback \\n#2019\\nLondon, UK @ Ab...</td>\n",
       "      <td>2021-04-30 03:23:21</td>\n",
       "      <td>Abbey Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@martjdayo @robnitm It's back in London at Can...</td>\n",
       "      <td>2021-04-28 16:28:29</td>\n",
       "      <td>Abbey Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@noordinarypark @WUParks @LeeValleyPark @AMOrb...</td>\n",
       "      <td>2021-04-27 07:30:07</td>\n",
       "      <td>Abbey Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>@Ana_Mitras @Uber If they had the knowledge th...</td>\n",
       "      <td>2021-05-01 15:31:09</td>\n",
       "      <td>Barkingside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Labour brought in Devolution to Scotland, Wale...</td>\n",
       "      <td>2021-05-01 14:51:52</td>\n",
       "      <td>Barkingside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>My new list of no go areas hackney. Islington ...</td>\n",
       "      <td>2021-05-01 08:09:17</td>\n",
       "      <td>Barkingside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>@TfLTPH You have to ask why taxis have to over...</td>\n",
       "      <td>2021-05-01 07:01:08</td>\n",
       "      <td>Barkingside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Now things are starting to open post covid the...</td>\n",
       "      <td>2021-04-30 20:02:56</td>\n",
       "      <td>Barkingside</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets                date  \\\n",
       "0    @paintpeteuk @BBCRadio3 Have seen it performed... 2021-05-01 20:06:22   \n",
       "1    Just posted a photo @ Abbey Road, London, UK h... 2021-05-01 16:01:07   \n",
       "2    Abbey Road #throwback \\n#2019\\nLondon, UK @ Ab... 2021-04-30 03:23:21   \n",
       "3    @martjdayo @robnitm It's back in London at Can... 2021-04-28 16:28:29   \n",
       "4    @noordinarypark @WUParks @LeeValleyPark @AMOrb... 2021-04-27 07:30:07   \n",
       "..                                                 ...                 ...   \n",
       "114  @Ana_Mitras @Uber If they had the knowledge th... 2021-05-01 15:31:09   \n",
       "115  Labour brought in Devolution to Scotland, Wale... 2021-05-01 14:51:52   \n",
       "116  My new list of no go areas hackney. Islington ... 2021-05-01 08:09:17   \n",
       "117  @TfLTPH You have to ask why taxis have to over... 2021-05-01 07:01:08   \n",
       "118  Now things are starting to open post covid the... 2021-04-30 20:02:56   \n",
       "\n",
       "         station  \n",
       "0     Abbey Road  \n",
       "1     Abbey Road  \n",
       "2     Abbey Road  \n",
       "3     Abbey Road  \n",
       "4     Abbey Road  \n",
       "..           ...  \n",
       "114  Barkingside  \n",
       "115  Barkingside  \n",
       "116  Barkingside  \n",
       "117  Barkingside  \n",
       "118  Barkingside  \n",
       "\n",
       "[119 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test-wed.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/christopherkindl/Desktop/wed_test_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/Users/christopherkindl/Desktop/df_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/Users/christopherkindl/Desktop/df_2.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/Users/christopherkindl/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blob(sentence):\n",
    "    temp = TextBlob(sentence).sentiment[0]\n",
    "    if temp == 0.0:\n",
    "        return 0.0 # Neutral\n",
    "    elif temp >= 0.0:\n",
    "        return 1.0 # Positive\n",
    "    else:\n",
    "        return 2.0 # Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Make sure that you dont sound to cooperate!'\n",
    "vs = analyzer.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.73, 'pos': 0.27, 'compound': 0.3802}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vader(sentence):\n",
    "    vs = analyzer.polarity_scores(sentence)    \n",
    "    return float(round(vs.get('compound'), 2))\n",
    "\n",
    "# assign sentiment function as an user defined function\n",
    "sentiment = udf(apply_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-------------+---------+\n",
      "|_c0|              tweets|               date|      station|sentiment|\n",
      "+---+--------------------+-------------------+-------------+---------+\n",
      "|  0|In #Newham today,...|2021-04-20 20:15:20|   Abbey Road|     0.62|\n",
      "|  1|While there is ma...|2021-04-19 11:26:43|   Abbey Road|     0.42|\n",
      "|  2|Just posted a pho...|2021-04-20 07:00:25|   Abbey Wood|      0.0|\n",
      "|  3|Walking on the wi...|2021-04-21 16:20:23|Acton Central|      0.0|\n",
      "|  4|Just posted a vid...|2021-04-19 17:03:53|Acton Central|      0.0|\n",
      "+---+--------------------+-------------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('SentimentAnalysis').getOrCreate()\n",
    "df_raw = spark.read.option('header', True).csv('/Users/christopherkindl/working/twitter_output_1.csv')\n",
    "df_clean = df_raw.withColumn('sentiment', sentiment(df_raw['tweets']))\n",
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.option('header', True).csv('/Users/christopherkindl/working/twitter_output_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas df first to avoid folder creation which happens when using spark csv function and export to csv\n",
    "header = [\"tweets\", \"date\", \"station\", \"sentiment\"]\n",
    "df_clean.toPandas().to_csv('/Users/christopherkindl/desktop/twitter_output_20.csv', columns = header, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.write.option(\"header\", \"true\").csv('/Users/christopherkindl/desktop/twitter_output_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 5, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-49802276ad56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/christopherkindl/Downloads/part-00000-2fa948e0-9e67-43f1-9945-e35174ac3279-c000.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 5, saw 5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/christopherkindl/Downloads/part-00000-2fa948e0-9e67-43f1-9945-e35174ac3279-c000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
